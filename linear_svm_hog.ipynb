{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from past.builtins import xrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training data features\n",
    "trainX = np.loadtxt('train_hog_features.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test data features\n",
    "testX = np.loadtxt('test_hog_features.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testX[:,0:-1]\n",
    "y_test = testX[:,-1].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing train data into train and validation (random)\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainX[:,0:-1], trainX[:,-1].astype(np.int32), test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train,(y_train.shape[0]))\n",
    "y_val = np.reshape(y_val,(y_val.shape[0]))\n",
    "y_test = np.reshape(y_test,(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding bias term\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 1297), (12000, 1297), (10000, 1297))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_val.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(W, X, y, reg):\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    C = W.shape[1]\n",
    "    \n",
    "    #compute scores\n",
    "    scores = X.dot(W) # N x C\n",
    "    \n",
    "    # Record the score of the example's correct class\n",
    "    correct_class_idx = tuple([range(scores.shape[0]), y])\n",
    "    correct_class_scores = scores[correct_class_idx]\n",
    "    \n",
    "    \n",
    "    # Compute for the margin by getting the max between 0 and the computed expression\n",
    "    losses = scores - np.reshape(correct_class_scores,(scores.shape[0],1)) + 1\n",
    "    losses[correct_class_idx] = 0\n",
    "    losses = losses.clip(min=0)\n",
    "    loss = np.sum(losses)\n",
    "    \n",
    "    # This mask can flag the examples in which their margin is greater than 0\n",
    "    dscores = np.zeros((N,C))\n",
    "    dscores[losses > 0] = 1\n",
    "    \n",
    "    d_correct_score = - np.sum(dscores, axis=1)\n",
    "    dscores[correct_class_idx] = d_correct_score\n",
    "    dW = X.T.dot(dscores)\n",
    "    \n",
    "    #Average\n",
    "    loss /= N\n",
    "    dW /= N\n",
    "    \n",
    "    #Regulariztion\n",
    "    loss += reg * np.sum(W * W)\n",
    "    dW += reg * 2 * W\n",
    "\n",
    "    return loss,dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1297, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "              batch_size=86, show_loss=False):\n",
    "        num_train, dim = X.shape\n",
    "        num_classes = np.max(y) + 1 \n",
    "        \n",
    "        W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        for it in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "\n",
    "            indices = np.random.choice(num_train, size=batch_size)\n",
    "            X_batch = X[indices]\n",
    "            y_batch = y[indices]\n",
    "\n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = svm_loss(W,X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            W -= learning_rate * grad\n",
    "\n",
    "\n",
    "            if show_loss and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "        return loss_history,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,W):\n",
    "    scores = X.dot(W)\n",
    "    y_pred = np.argmax(scores, axis=1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 3000: loss 8.997354\n",
      "iteration 100 / 3000: loss 0.560957\n",
      "iteration 200 / 3000: loss 0.721955\n",
      "iteration 300 / 3000: loss 0.669788\n",
      "iteration 400 / 3000: loss 0.460385\n",
      "iteration 500 / 3000: loss 0.496999\n",
      "iteration 600 / 3000: loss 0.499534\n",
      "iteration 700 / 3000: loss 0.408102\n",
      "iteration 800 / 3000: loss 0.700294\n",
      "iteration 900 / 3000: loss 0.331767\n",
      "iteration 1000 / 3000: loss 0.408700\n",
      "iteration 1100 / 3000: loss 0.496536\n",
      "iteration 1200 / 3000: loss 0.345201\n",
      "iteration 1300 / 3000: loss 0.202409\n",
      "iteration 1400 / 3000: loss 0.214422\n",
      "iteration 1500 / 3000: loss 0.223331\n",
      "iteration 1600 / 3000: loss 0.372012\n",
      "iteration 1700 / 3000: loss 0.577993\n",
      "iteration 1800 / 3000: loss 0.572366\n",
      "iteration 1900 / 3000: loss 0.342600\n",
      "iteration 2000 / 3000: loss 0.583307\n",
      "iteration 2100 / 3000: loss 0.355529\n",
      "iteration 2200 / 3000: loss 0.431704\n",
      "iteration 2300 / 3000: loss 0.592148\n",
      "iteration 2400 / 3000: loss 0.536860\n",
      "iteration 2500 / 3000: loss 0.420846\n",
      "iteration 2600 / 3000: loss 0.437266\n",
      "iteration 2700 / 3000: loss 0.282024\n",
      "iteration 2800 / 3000: loss 0.365512\n",
      "iteration 2900 / 3000: loss 0.403504\n"
     ]
    }
   ],
   "source": [
    "loss_hist,W = train(X_train, y_train, learning_rate=0.1, reg=0.0001,\n",
    "                      num_iters=3000, show_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-398fbb3320ff>:36: RuntimeWarning: overflow encountered in multiply\n",
      "  loss += reg * np.sum(W * W)\n",
      "<ipython-input-9-398fbb3320ff>:18: RuntimeWarning: overflow encountered in subtract\n",
      "  losses = scores - np.reshape(correct_class_scores,(scores.shape[0],1)) + 1\n",
      "<ipython-input-9-398fbb3320ff>:18: RuntimeWarning: invalid value encountered in subtract\n",
      "  losses = scores - np.reshape(correct_class_scores,(scores.shape[0],1)) + 1\n",
      "<ipython-input-9-398fbb3320ff>:37: RuntimeWarning: overflow encountered in multiply\n",
      "  dW += reg * 2 * W\n",
      "<ipython-input-10-a8ef0988ae5f>:22: RuntimeWarning: invalid value encountered in subtract\n",
      "  W -= learning_rate * grad\n",
      "<ipython-input-9-398fbb3320ff>:36: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += reg * np.sum(W * W)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a8ef0988ae5f>:22: RuntimeWarning: overflow encountered in multiply\n",
      "  W -= learning_rate * grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "lr 1.000000e-06 reg 1.000000e-06 train accuracy: 0.470042 val accuracy: 0.468667\n",
      "lr 1.000000e-06 reg 1.000000e-05 train accuracy: 0.426521 val accuracy: 0.430833\n",
      "lr 1.000000e-06 reg 1.000000e-04 train accuracy: 0.424083 val accuracy: 0.429000\n",
      "lr 1.000000e-06 reg 1.000000e-03 train accuracy: 0.438021 val accuracy: 0.438750\n",
      "lr 1.000000e-06 reg 1.000000e-02 train accuracy: 0.424771 val accuracy: 0.430500\n",
      "lr 1.000000e-06 reg 1.000000e-01 train accuracy: 0.422396 val accuracy: 0.424750\n",
      "lr 1.000000e-06 reg 1.000000e+00 train accuracy: 0.465292 val accuracy: 0.472583\n",
      "lr 1.000000e-06 reg 2.000000e+00 train accuracy: 0.425146 val accuracy: 0.424167\n",
      "lr 1.000000e-06 reg 3.000000e+00 train accuracy: 0.431000 val accuracy: 0.433083\n",
      "lr 1.000000e-06 reg 4.000000e+00 train accuracy: 0.501646 val accuracy: 0.495583\n",
      "lr 1.000000e-06 reg 5.000000e+00 train accuracy: 0.415187 val accuracy: 0.423750\n",
      "lr 1.000000e-06 reg 6.000000e+00 train accuracy: 0.425042 val accuracy: 0.430000\n",
      "lr 1.000000e-06 reg 7.000000e+00 train accuracy: 0.492729 val accuracy: 0.498000\n",
      "lr 1.000000e-06 reg 8.000000e+00 train accuracy: 0.380063 val accuracy: 0.377500\n",
      "lr 1.000000e-06 reg 9.000000e+00 train accuracy: 0.514479 val accuracy: 0.514833\n",
      "lr 1.000000e-06 reg 1.000000e+01 train accuracy: 0.453917 val accuracy: 0.458083\n",
      "lr 1.000000e-05 reg 1.000000e-06 train accuracy: 0.648333 val accuracy: 0.649167\n",
      "lr 1.000000e-05 reg 1.000000e-05 train accuracy: 0.625875 val accuracy: 0.634000\n",
      "lr 1.000000e-05 reg 1.000000e-04 train accuracy: 0.658479 val accuracy: 0.662250\n",
      "lr 1.000000e-05 reg 1.000000e-03 train accuracy: 0.605979 val accuracy: 0.611917\n",
      "lr 1.000000e-05 reg 1.000000e-02 train accuracy: 0.658563 val accuracy: 0.661083\n",
      "lr 1.000000e-05 reg 1.000000e-01 train accuracy: 0.626542 val accuracy: 0.635833\n",
      "lr 1.000000e-05 reg 1.000000e+00 train accuracy: 0.623604 val accuracy: 0.629250\n",
      "lr 1.000000e-05 reg 2.000000e+00 train accuracy: 0.645062 val accuracy: 0.649583\n",
      "lr 1.000000e-05 reg 3.000000e+00 train accuracy: 0.601562 val accuracy: 0.607167\n",
      "lr 1.000000e-05 reg 4.000000e+00 train accuracy: 0.639458 val accuracy: 0.646167\n",
      "lr 1.000000e-05 reg 5.000000e+00 train accuracy: 0.647625 val accuracy: 0.654167\n",
      "lr 1.000000e-05 reg 6.000000e+00 train accuracy: 0.654875 val accuracy: 0.656500\n",
      "lr 1.000000e-05 reg 7.000000e+00 train accuracy: 0.630000 val accuracy: 0.634000\n",
      "lr 1.000000e-05 reg 8.000000e+00 train accuracy: 0.648479 val accuracy: 0.652917\n",
      "lr 1.000000e-05 reg 9.000000e+00 train accuracy: 0.623583 val accuracy: 0.628833\n",
      "lr 1.000000e-05 reg 1.000000e+01 train accuracy: 0.673417 val accuracy: 0.677417\n",
      "lr 1.000000e-04 reg 1.000000e-06 train accuracy: 0.776271 val accuracy: 0.775500\n",
      "lr 1.000000e-04 reg 1.000000e-05 train accuracy: 0.772646 val accuracy: 0.774083\n",
      "lr 1.000000e-04 reg 1.000000e-04 train accuracy: 0.775563 val accuracy: 0.776417\n",
      "lr 1.000000e-04 reg 1.000000e-03 train accuracy: 0.770000 val accuracy: 0.772750\n",
      "lr 1.000000e-04 reg 1.000000e-02 train accuracy: 0.771167 val accuracy: 0.772167\n",
      "lr 1.000000e-04 reg 1.000000e-01 train accuracy: 0.770958 val accuracy: 0.771667\n",
      "lr 1.000000e-04 reg 1.000000e+00 train accuracy: 0.772062 val accuracy: 0.770667\n",
      "lr 1.000000e-04 reg 2.000000e+00 train accuracy: 0.765813 val accuracy: 0.766583\n",
      "lr 1.000000e-04 reg 3.000000e+00 train accuracy: 0.758167 val accuracy: 0.756750\n",
      "lr 1.000000e-04 reg 4.000000e+00 train accuracy: 0.750458 val accuracy: 0.751000\n",
      "lr 1.000000e-04 reg 5.000000e+00 train accuracy: 0.719917 val accuracy: 0.724583\n",
      "lr 1.000000e-04 reg 6.000000e+00 train accuracy: 0.698958 val accuracy: 0.702000\n",
      "lr 1.000000e-04 reg 7.000000e+00 train accuracy: 0.688458 val accuracy: 0.691667\n",
      "lr 1.000000e-04 reg 8.000000e+00 train accuracy: 0.669188 val accuracy: 0.673750\n",
      "lr 1.000000e-04 reg 9.000000e+00 train accuracy: 0.641917 val accuracy: 0.646500\n",
      "lr 1.000000e-04 reg 1.000000e+01 train accuracy: 0.655229 val accuracy: 0.660500\n",
      "lr 1.000000e-03 reg 1.000000e-06 train accuracy: 0.801813 val accuracy: 0.805333\n",
      "lr 1.000000e-03 reg 1.000000e-05 train accuracy: 0.801125 val accuracy: 0.803833\n",
      "lr 1.000000e-03 reg 1.000000e-04 train accuracy: 0.803271 val accuracy: 0.805000\n",
      "lr 1.000000e-03 reg 1.000000e-03 train accuracy: 0.803583 val accuracy: 0.806917\n",
      "lr 1.000000e-03 reg 1.000000e-02 train accuracy: 0.801292 val accuracy: 0.804333\n",
      "lr 1.000000e-03 reg 1.000000e-01 train accuracy: 0.799875 val accuracy: 0.802333\n",
      "lr 1.000000e-03 reg 1.000000e+00 train accuracy: 0.796188 val accuracy: 0.793500\n",
      "lr 1.000000e-03 reg 2.000000e+00 train accuracy: 0.784000 val accuracy: 0.783083\n",
      "lr 1.000000e-03 reg 3.000000e+00 train accuracy: 0.764250 val accuracy: 0.763750\n",
      "lr 1.000000e-03 reg 4.000000e+00 train accuracy: 0.778854 val accuracy: 0.774500\n",
      "lr 1.000000e-03 reg 5.000000e+00 train accuracy: 0.752271 val accuracy: 0.753250\n",
      "lr 1.000000e-03 reg 6.000000e+00 train accuracy: 0.759521 val accuracy: 0.756750\n",
      "lr 1.000000e-03 reg 7.000000e+00 train accuracy: 0.708521 val accuracy: 0.710417\n",
      "lr 1.000000e-03 reg 8.000000e+00 train accuracy: 0.665188 val accuracy: 0.669917\n",
      "lr 1.000000e-03 reg 9.000000e+00 train accuracy: 0.647167 val accuracy: 0.656833\n",
      "lr 1.000000e-03 reg 1.000000e+01 train accuracy: 0.659375 val accuracy: 0.664750\n",
      "lr 1.000000e-02 reg 1.000000e-06 train accuracy: 0.854250 val accuracy: 0.848417\n",
      "lr 1.000000e-02 reg 1.000000e-05 train accuracy: 0.855125 val accuracy: 0.849917\n",
      "lr 1.000000e-02 reg 1.000000e-04 train accuracy: 0.855437 val accuracy: 0.851083\n",
      "lr 1.000000e-02 reg 1.000000e-03 train accuracy: 0.855917 val accuracy: 0.850333\n",
      "lr 1.000000e-02 reg 1.000000e-02 train accuracy: 0.853688 val accuracy: 0.850417\n",
      "lr 1.000000e-02 reg 1.000000e-01 train accuracy: 0.836917 val accuracy: 0.834417\n",
      "lr 1.000000e-02 reg 1.000000e+00 train accuracy: 0.791875 val accuracy: 0.791583\n",
      "lr 1.000000e-02 reg 2.000000e+00 train accuracy: 0.757625 val accuracy: 0.757167\n",
      "lr 1.000000e-02 reg 3.000000e+00 train accuracy: 0.666917 val accuracy: 0.665083\n",
      "lr 1.000000e-02 reg 4.000000e+00 train accuracy: 0.754833 val accuracy: 0.754083\n",
      "lr 1.000000e-02 reg 5.000000e+00 train accuracy: 0.708958 val accuracy: 0.708333\n",
      "lr 1.000000e-02 reg 6.000000e+00 train accuracy: 0.617396 val accuracy: 0.626917\n",
      "lr 1.000000e-02 reg 7.000000e+00 train accuracy: 0.610688 val accuracy: 0.614417\n",
      "lr 1.000000e-02 reg 8.000000e+00 train accuracy: 0.628604 val accuracy: 0.628417\n",
      "lr 1.000000e-02 reg 9.000000e+00 train accuracy: 0.575021 val accuracy: 0.577583\n",
      "lr 1.000000e-02 reg 1.000000e+01 train accuracy: 0.516188 val accuracy: 0.518500\n",
      "lr 1.000000e-01 reg 1.000000e-06 train accuracy: 0.884437 val accuracy: 0.872167\n",
      "lr 1.000000e-01 reg 1.000000e-05 train accuracy: 0.882104 val accuracy: 0.873833\n",
      "lr 1.000000e-01 reg 1.000000e-04 train accuracy: 0.882896 val accuracy: 0.874833\n",
      "lr 1.000000e-01 reg 1.000000e-03 train accuracy: 0.878563 val accuracy: 0.866833\n",
      "lr 1.000000e-01 reg 1.000000e-02 train accuracy: 0.866229 val accuracy: 0.859667\n",
      "lr 1.000000e-01 reg 1.000000e-01 train accuracy: 0.779271 val accuracy: 0.782250\n",
      "lr 1.000000e-01 reg 1.000000e+00 train accuracy: 0.474146 val accuracy: 0.481417\n",
      "lr 1.000000e-01 reg 2.000000e+00 train accuracy: 0.374229 val accuracy: 0.381417\n",
      "lr 1.000000e-01 reg 3.000000e+00 train accuracy: 0.338458 val accuracy: 0.330667\n",
      "lr 1.000000e-01 reg 4.000000e+00 train accuracy: 0.481417 val accuracy: 0.480667\n",
      "lr 1.000000e-01 reg 5.000000e+00 train accuracy: 0.298625 val accuracy: 0.296833\n",
      "lr 1.000000e-01 reg 6.000000e+00 train accuracy: 0.332354 val accuracy: 0.324500\n",
      "lr 1.000000e-01 reg 7.000000e+00 train accuracy: 0.370104 val accuracy: 0.371500\n",
      "lr 1.000000e-01 reg 8.000000e+00 train accuracy: 0.350187 val accuracy: 0.345667\n",
      "lr 1.000000e-01 reg 9.000000e+00 train accuracy: 0.193458 val accuracy: 0.193417\n",
      "lr 1.000000e-01 reg 1.000000e+01 train accuracy: 0.200375 val accuracy: 0.210417\n",
      "lr 1.000000e+00 reg 1.000000e-06 train accuracy: 0.876979 val accuracy: 0.861167\n",
      "lr 1.000000e+00 reg 1.000000e-05 train accuracy: 0.890500 val accuracy: 0.870917\n",
      "lr 1.000000e+00 reg 1.000000e-04 train accuracy: 0.829812 val accuracy: 0.815917\n",
      "lr 1.000000e+00 reg 1.000000e-03 train accuracy: 0.830646 val accuracy: 0.822583\n",
      "lr 1.000000e+00 reg 1.000000e-02 train accuracy: 0.691667 val accuracy: 0.697333\n",
      "lr 1.000000e+00 reg 1.000000e-01 train accuracy: 0.312896 val accuracy: 0.317500\n",
      "lr 1.000000e+00 reg 1.000000e+00 train accuracy: 0.162000 val accuracy: 0.156833\n",
      "lr 1.000000e+00 reg 2.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 3.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 4.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 5.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 6.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 7.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 8.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 9.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 1.000000e+00 reg 1.000000e+01 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 1.000000e-06 train accuracy: 0.884583 val accuracy: 0.869167\n",
      "lr 2.000000e+00 reg 1.000000e-05 train accuracy: 0.828313 val accuracy: 0.815500\n",
      "lr 2.000000e+00 reg 1.000000e-04 train accuracy: 0.856333 val accuracy: 0.844000\n",
      "lr 2.000000e+00 reg 1.000000e-03 train accuracy: 0.829729 val accuracy: 0.819500\n",
      "lr 2.000000e+00 reg 1.000000e-02 train accuracy: 0.578917 val accuracy: 0.576167\n",
      "lr 2.000000e+00 reg 1.000000e-01 train accuracy: 0.352771 val accuracy: 0.355833\n",
      "lr 2.000000e+00 reg 1.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 2.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 3.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 4.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 5.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 6.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 7.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 8.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 9.000000e+00 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "lr 2.000000e+00 reg 1.000000e+01 train accuracy: 0.099500 val accuracy: 0.102000\n",
      "best validation accuracy achieved during cross-validation: 0.874833\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,2]\n",
    "regularization_strengths = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# results is dictionary mapping tuples of the form\n",
    "# (learning_rate, regularization_strength) to tuples of the form\n",
    "# (training_accuracy, validation_accuracy)\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "\n",
    "\n",
    "count = 0\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss,W = train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500, show_loss=False)\n",
    "        y_train_pred = predict(X_train,W)\n",
    "        train_accu = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = predict(X_val,W)\n",
    "        val_accu = np.mean(y_val == y_val_pred)\n",
    "        results[(lr, reg)] = (train_accu, val_accu)\n",
    "        if  best_val == -1 or val_accu > best_val:\n",
    "            best_val = val_accu\n",
    "        count += 1\n",
    "        if(count % 10 == 0):\n",
    "            print(count)\n",
    "\n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.890062\n",
      "validation accuracy: 0.873750\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of train and validation\n",
    "y_train_pred = predict(X_train,W)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = predict(X_val,W)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 0 ... 0 4 5] [7 7 0 ... 0 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM on HOG Extracted features final test set accuracy: 0.886300\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = predict(X_test,W)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('linear SVM on HOG Extracted features final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
