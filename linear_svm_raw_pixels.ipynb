{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from past.builtins import xrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training data features\n",
    "train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "trainX = train.loc[:,train.columns != 'label'].to_numpy()\n",
    "trainX = trainX.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test data features\n",
    "test = pd.read_csv(\"fashion-mnist_test.csv\")\n",
    "X_test = test.loc[:,test.columns != 'label'].to_numpy()\n",
    "X_test = X_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test labels\n",
    "y_test = test.iloc[:,test.columns == 'label'].to_numpy()\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training data labels\n",
    "trainY = train.iloc[:,test.columns == 'label'].to_numpy()\n",
    "trainY = trainY.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing train data into train and validation (random)\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainX, trainY, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train,(y_train.shape[0]))\n",
    "y_val = np.reshape(y_val,(y_val.shape[0]))\n",
    "y_test = np.reshape(y_test,(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding bias term\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 785), (12000, 785), (10000, 785))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_val.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(W, X, y, reg):\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    C = W.shape[1]\n",
    "    \n",
    "    #compute scores\n",
    "    scores = X.dot(W) # N x C\n",
    "    \n",
    "    # Record the score of the example's correct class\n",
    "    correct_class_idx = tuple([range(scores.shape[0]), y])\n",
    "    correct_class_scores = scores[correct_class_idx]\n",
    "    \n",
    "    # Compute for the margin by getting the max between 0 and the computed expression\n",
    "    losses = scores - np.reshape(correct_class_scores,(scores.shape[0],1)) + 1\n",
    "    losses[correct_class_idx] = 0\n",
    "    losses = losses.clip(min=0)\n",
    "    loss = np.sum(losses)\n",
    "    \n",
    "    # This mask can flag the examples in which their margin is greater than 0\n",
    "    dscores = np.zeros((N,C))\n",
    "    dscores[losses > 0] = 1\n",
    "    d_correct_score = - np.sum(dscores, axis=1)\n",
    "    dscores[correct_class_idx] = d_correct_score\n",
    "    dW = X.T.dot(dscores)\n",
    "    \n",
    "    #Average\n",
    "    loss /= N\n",
    "    dW /= N\n",
    "    \n",
    "    #Regulariztion\n",
    "    loss += reg * np.sum(W * W)\n",
    "    dW += reg * 2 * W\n",
    "\n",
    "    return loss,dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(785, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "y = np.reshape(y_train,(y_train.shape[0]))\n",
    "loss,dw = svm_loss(W,X_train[0:120,:],y[0:120],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "              batch_size=120, show_loss=False):\n",
    "        num_train, dim = X.shape\n",
    "        num_classes = np.max(y) + 1 \n",
    "        \n",
    "        W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "        start = 0\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        for it in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "            \n",
    "            indices = np.random.choice(num_train, size=batch_size)\n",
    "            X_batch = X[indices]\n",
    "            y_batch = y[indices]\n",
    "\n",
    "\n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = svm_loss(W,X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            W -= learning_rate * grad\n",
    "\n",
    "\n",
    "            if show_loss and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "        return loss_history,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,W):\n",
    "    scores = X.dot(W)\n",
    "    y_pred = np.argmax(scores, axis=1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2000: loss 18.688738\n",
      "iteration 100 / 2000: loss 2.513861\n",
      "iteration 200 / 2000: loss 2.350509\n",
      "iteration 300 / 2000: loss 2.168045\n",
      "iteration 400 / 2000: loss 1.811276\n",
      "iteration 500 / 2000: loss 6.666360\n",
      "iteration 600 / 2000: loss 2.948842\n",
      "iteration 700 / 2000: loss 5.234330\n",
      "iteration 800 / 2000: loss 2.850373\n",
      "iteration 900 / 2000: loss 1.969431\n",
      "iteration 1000 / 2000: loss 2.305958\n",
      "iteration 1100 / 2000: loss 3.157930\n",
      "iteration 1200 / 2000: loss 1.539895\n",
      "iteration 1300 / 2000: loss 2.833641\n",
      "iteration 1400 / 2000: loss 1.569824\n",
      "iteration 1500 / 2000: loss 4.432980\n",
      "iteration 1600 / 2000: loss 3.069718\n",
      "iteration 1700 / 2000: loss 2.440557\n",
      "iteration 1800 / 2000: loss 2.482753\n",
      "iteration 1900 / 2000: loss 3.866976\n"
     ]
    }
   ],
   "source": [
    "loss_hist,W = train(X_train, y_train, learning_rate=1e-5, reg=4.6,\n",
    "                      num_iters=2000, show_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.839521\n",
      "validation accuracy: 0.833083\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of train and validation\n",
    "y_train_pred = predict(X_train,W)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = predict(X_val,W)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [5]\n",
      " [2]\n",
      " ...\n",
      " [7]\n",
      " [3]\n",
      " [9]] [1 5 2 ... 7 3 9]\n"
     ]
    }
   ],
   "source": [
    "print(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM on raw pixels final test set accuracy: 0.836000\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = predict(X_test,W)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('linear SVM on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
